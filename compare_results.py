#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
å¯¹æ¯”è¯„ä¼°è„šæœ¬ - å¯¹æ¯”åŸºçº¿æ¨¡å‹å’Œ P2 æ¨¡å‹çš„æ€§èƒ½
"""
import os
import sys
from pathlib import Path

def main():
    project_root = Path(__file__).parent.absolute()
    os.chdir(project_root)
    
    from ultralytics import YOLO
    
    # æ•°æ®é…ç½®æ–‡ä»¶
    data_yaml = project_root / "cfg" / "visdrone.yaml"
    
    # æŸ¥æ‰¾æ¨¡å‹æƒé‡ï¼ˆæ”¯æŒå¤šä¸ªæ¨¡å‹å¯¹æ¯”ï¼‰
    models_to_eval = []
    
    # Baseline æ¨¡å‹
    baseline_weights = project_root / "runs" / "visdrone" / "baseline_y8s_1024_adamw" / "weights" / "best.pt"
    if baseline_weights.exists():
        models_to_eval.append(("Baseline (YOLOv8s)", baseline_weights))
    else:
        print(f"âš  è­¦å‘Š: åŸºçº¿æ¨¡å‹æƒé‡ä¸å­˜åœ¨: {baseline_weights}")
    
    # P2 æ¨¡å‹
    p2_weights = project_root / "runs" / "visdrone" / "y8s_p2_1024_adamw_bs4" / "weights" / "best.pt"
    if not p2_weights.exists():
        # å°è¯•æŸ¥æ‰¾å…¶ä»–å¯èƒ½çš„è·¯å¾„
        p2_dirs = list((project_root / "runs" / "visdrone").glob("y8s_p2*"))
        p2_dirs = [d for d in p2_dirs if 'bifpn' not in d.name.lower()]  # æ’é™¤ BiFPN
        if p2_dirs:
            p2_weights = p2_dirs[0] / "weights" / "best.pt"
    
    if p2_weights.exists():
        models_to_eval.append(("P2 Model (YOLOv8s-P2)", p2_weights))
    else:
        print(f"âš  è­¦å‘Š: P2 æ¨¡å‹æƒé‡ä¸å­˜åœ¨")
    
    # P2 + BiFPN æ¨¡å‹
    bifpn_weights = project_root / "runs" / "visdrone" / "y8s_p2_bifpn_1024_adamw" / "weights" / "best.pt"
    if not bifpn_weights.exists():
        # å°è¯•æŸ¥æ‰¾å…¶ä»–å¯èƒ½çš„è·¯å¾„
        bifpn_dirs = list((project_root / "runs" / "visdrone").glob("*bifpn*"))
        if bifpn_dirs:
            bifpn_weights = bifpn_dirs[0] / "weights" / "best.pt"
    
    if bifpn_weights.exists():
        models_to_eval.append(("P2+BiFPN (YOLOv8s-P2-BiFPN)", bifpn_weights))
    else:
        print(f"âš  æç¤º: P2+BiFPN æ¨¡å‹æƒé‡ä¸å­˜åœ¨ï¼ˆå¯èƒ½è¿˜åœ¨è®­ç»ƒä¸­ï¼‰")
    
    if len(models_to_eval) == 0:
        print("é”™è¯¯: æ‰¾ä¸åˆ°ä»»ä½•æ¨¡å‹æƒé‡æ–‡ä»¶")
        sys.exit(1)
    
    results_summary = []
    
    print("=" * 70)
    print("æ¨¡å‹æ€§èƒ½å¯¹æ¯”è¯„ä¼°")
    print("=" * 70)
    
    for model_name, model_path in models_to_eval:
        print(f"\nè¯„ä¼°æ¨¡å‹: {model_name}")
        print(f"æƒé‡è·¯å¾„: {model_path}")
        print("-" * 70)
        
        try:
            model = YOLO(str(model_path))
            
            # è¿è¡Œè¯„ä¼°
            eval_results = model.val(
                data=str(data_yaml),
                imgsz=1024,
                batch=1,
                conf=0.25,
                iou=0.7,
                device=0,
                verbose=True,
                save_json=False,
            )
            
            # æå–å…³é”®æŒ‡æ ‡
            summary = {
                'model_name': model_name,
                'map50': eval_results.box.map50,
                'map50_95': eval_results.box.map,
                'precision': eval_results.box.p[0] if hasattr(eval_results.box, 'p') else 0,
                'recall': eval_results.box.r[0] if hasattr(eval_results.box, 'r') else 0,
                'f1': eval_results.box.f[0] if hasattr(eval_results.box, 'f') else 0,
            }
            
            # æå–æ¯ä¸ªç±»åˆ«çš„ AP
            if hasattr(eval_results.box, 'maps') and len(eval_results.box.maps) > 0:
                class_names = ['pedestrian', 'people', 'bicycle', 'car', 'van', 
                             'truck', 'tricycle', 'awning-tricycle', 'bus', 'motor']
                summary['class_aps'] = {}
                for i, name in enumerate(class_names):
                    if i < len(eval_results.box.maps):
                        summary['class_aps'][name] = eval_results.box.maps[i]
            
            results_summary.append(summary)
            
            print(f"âœ“ mAP50: {summary['map50']:.4f}")
            print(f"âœ“ mAP50-95: {summary['map50_95']:.4f}")
            print(f"âœ“ Precision: {summary['precision']:.4f}")
            print(f"âœ“ Recall: {summary['recall']:.4f}")
            print(f"âœ“ F1: {summary['f1']:.4f}")
            
        except Exception as e:
            print(f"âœ— è¯„ä¼°å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            continue
    
    # å¯¹æ¯”ç»“æœ
    if len(results_summary) >= 2:
        print("\n" + "=" * 70)
        print("æ€§èƒ½å¯¹æ¯”æ€»ç»“")
        print("=" * 70)
        
        baseline = results_summary[0]
        other_models = results_summary[1:]
        
        # æ„å»ºè¡¨å¤´
        header = f"{'æŒ‡æ ‡':<20}"
        for model_name, _ in models_to_eval:
            short_name = model_name.split('(')[0].strip() if '(' in model_name else model_name[:12]
            header += f" {short_name:<18}"
        if len(other_models) > 0:
            header += f" {'vs Baseline':<15}"
        print(header)
        print("-" * 70)
        
        metrics = [
            ('mAP50', 'map50'),
            ('mAP50-95', 'map50_95'),
            ('Precision', 'precision'),
            ('Recall', 'recall'),
            ('F1-Score', 'f1'),
        ]
        
        for metric_name, metric_key in metrics:
            row = f"{metric_name:<20}"
            baseline_val = baseline[metric_key]
            row += f" {baseline_val:<18.4f}"
            
            for other_model in other_models:
                other_val = other_model[metric_key]
                row += f" {other_val:<18.4f}"
            
            # è®¡ç®—ç›¸å¯¹åŸºçº¿çš„æå‡
            if len(other_models) > 0:
                best_val = max([m[metric_key] for m in other_models])
                improvement = best_val - baseline_val
                improvement_pct = (improvement / baseline_val * 100) if baseline_val > 0 else 0
                row += f" {improvement:+.4f} ({improvement_pct:+.2f}%)"
            
            print(row)
        
        # å°ç›®æ ‡ç±»åˆ«å¯¹æ¯”
        if 'class_aps' in baseline:
            print("\n" + "-" * 70)
            print("å°ç›®æ ‡ç±»åˆ«è¯¦ç»†å¯¹æ¯” (mAP50-95)")
            print("-" * 70)
            
            small_target_classes = ['pedestrian', 'people', 'bicycle', 'motor', 'tricycle', 'awning-tricycle']
            
            for cls in small_target_classes:
                if cls in baseline['class_aps']:
                    row = f"{cls:<20}"
                    baseline_ap = baseline['class_aps'][cls]
                    row += f" {baseline_ap:<18.4f}"
                    
                    best_improvement = 0
                    for other_model in other_models:
                        if 'class_aps' in other_model and cls in other_model['class_aps']:
                            other_ap = other_model['class_aps'][cls]
                            row += f" {other_ap:<18.4f}"
                            improvement = other_ap - baseline_ap
                            if improvement > best_improvement:
                                best_improvement = improvement
                        else:
                            row += f" {'N/A':<18}"
                    
                    if best_improvement != 0:
                        improvement_pct = (best_improvement / baseline_ap * 100) if baseline_ap > 0 else 0
                        row += f" {best_improvement:+.4f} ({improvement_pct:+.2f}%)"
                    
                    print(row)
        
        print("\n" + "=" * 70)
        print("ç»“è®º:")
        baseline_map = baseline['map50_95']
        
        for i, other_model in enumerate(other_models):
            model_name = other_models[i]['model_name']
            improvement = other_model['map50_95'] - baseline_map
            
            if improvement > 0.01:
                print(f"âœ“ {model_name} ç›¸æ¯”åŸºçº¿æœ‰æ˜¾è‘—æå‡ (+{improvement:.4f} mAP50-95, +{improvement/baseline_map*100:.1f}%)")
            elif improvement > 0:
                print(f"âœ“ {model_name} ç›¸æ¯”åŸºçº¿æœ‰è½»å¾®æå‡ (+{improvement:.4f} mAP50-95, +{improvement/baseline_map*100:.1f}%)")
            elif improvement > -0.01:
                print(f"â‰ˆ {model_name} ç›¸æ¯”åŸºçº¿åŸºæœ¬æŒå¹³ ({improvement:+.4f} mAP50-95)")
            else:
                print(f"âš  {model_name} ç›¸æ¯”åŸºçº¿ä¸‹é™äº† ({improvement:.4f} mAP50-95, {improvement/baseline_map*100:.1f}%)")
        
        # æ‰¾å‡ºæœ€ä½³æ¨¡å‹
        if len(other_models) > 0:
            best_model = max(other_models, key=lambda x: x['map50_95'])
            print(f"\nğŸ† æœ€ä½³æ¨¡å‹: {best_model['model_name']} (mAP50-95: {best_model['map50_95']:.4f})")
        
        print("=" * 70)
    
    # ä¿å­˜ç»“æœåˆ°æ–‡ä»¶
    output_file = project_root / "results" / "p2_comparison_summary.md"
    output_file.parent.mkdir(exist_ok=True)
    
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write("# P2 æ¨¡å‹æ€§èƒ½å¯¹æ¯”\n\n")
        f.write("## è¯„ä¼°ç»“æœ\n\n")
        
        for result in results_summary:
            f.write(f"### {result['model_name']}\n\n")
            f.write(f"- mAP50: {result['map50']:.4f}\n")
            f.write(f"- mAP50-95: {result['map50_95']:.4f}\n")
            f.write(f"- Precision: {result['precision']:.4f}\n")
            f.write(f"- Recall: {result['recall']:.4f}\n")
            f.write(f"- F1: {result['f1']:.4f}\n\n")
            
            if 'class_aps' in result:
                f.write("#### å„ç±»åˆ« mAP50-95\n\n")
                for cls, ap in result['class_aps'].items():
                    f.write(f"- {cls}: {ap:.4f}\n")
                f.write("\n")
        
        if len(results_summary) >= 2:
            f.write("## å¯¹æ¯”åˆ†æ\n\n")
            f.write(f"æ€»ä½“æå‡: {p2['map50_95'] - baseline['map50_95']:+.4f} mAP50-95\n")
    
    print(f"\nè¯¦ç»†ç»“æœå·²ä¿å­˜åˆ°: {output_file}")

if __name__ == '__main__':
    main()

