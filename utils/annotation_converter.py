#!/usr/bin/env python3
"""
VisDroneæ ‡æ³¨æ ¼å¼è½¬YOLOæ ¼å¼è½¬æ¢å™¨
"""

import os
import sys
from pathlib import Path
from tqdm import tqdm

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.append(str(project_root))

from utils.path_manager import path_manager


class AnnotationConverter:
    """æ ‡æ³¨æ ¼å¼è½¬æ¢å™¨"""

    def __init__(self):
        # VisDroneç±»åˆ«åˆ°YOLOç±»åˆ«çš„æ˜ å°„ï¼ˆå¿½ç•¥0å’Œ11ç±»åˆ«ï¼‰
        self.category_mapping = {
            1: 0,  # pedestrian -> 0
            2: 1,  # people -> 1
            3: 2,  # bicycle -> 2
            4: 3,  # car -> 3
            5: 4,  # van -> 4
            6: 5,  # truck -> 5
            7: 6,  # tricycle -> 6
            8: 7,  # awning-tricycle -> 7
            9: 8,  # bus -> 8
            10: 9,  # motor -> 9
            # å¿½ç•¥ 0: ignore, 11: others
        }

        # YOLOç±»åˆ«åç§°ï¼ˆæŒ‰æ˜ å°„åçš„é¡ºåºï¼‰
        self.yolo_class_names = [
            'pedestrian', 'people', 'bicycle', 'car', 'van',
            'truck', 'tricycle', 'awning-tricycle', 'bus', 'motor'
        ]

    def convert_annotation(self, annotation_path, image_width, image_height):
        """è½¬æ¢å•ä¸ªæ ‡æ³¨æ–‡ä»¶"""
        yolo_annotations = []

        try:
            with open(annotation_path, 'r', encoding='utf-8') as f:
                lines = f.readlines()
        except:
            print(f"âŒ æ— æ³•è¯»å–æ ‡æ³¨æ–‡ä»¶: {annotation_path}")
            return yolo_annotations

        for line in lines:
            line = line.strip()
            if not line:
                continue

            parts = line.split(',')
            if len(parts) < 8:
                continue

            try:
                # è§£æVisDroneæ ¼å¼
                bbox_left = float(parts[0])
                bbox_top = float(parts[1])
                bbox_width = float(parts[2])
                bbox_height = float(parts[3])
                object_category = int(parts[5])

                # è¿‡æ»¤æ— æ•ˆç›®æ ‡
                if object_category not in self.category_mapping:
                    continue

                # è¿‡æ»¤å°ç›®æ ‡ï¼ˆå¯é€‰ï¼‰
                if bbox_width < 2 or bbox_height < 2:
                    continue

                # è½¬æ¢ä¸ºYOLOæ ¼å¼
                x_center = (bbox_left + bbox_width / 2) / image_width
                y_center = (bbox_top + bbox_height / 2) / image_height
                width = bbox_width / image_width
                height = bbox_height / image_height

                # ç¡®ä¿åæ ‡åœ¨0-1èŒƒå›´å†…
                x_center = max(0, min(1, x_center))
                y_center = max(0, min(1, y_center))
                width = max(0, min(1, width))
                height = max(0, min(1, height))

                # è·³è¿‡æ— æ•ˆçš„è¾¹ç•Œæ¡†
                if width <= 0 or height <= 0:
                    continue

                # è·å–YOLOç±»åˆ«ID
                yolo_class_id = self.category_mapping[object_category]

                # æ·»åŠ åˆ°ç»“æœ
                yolo_annotations.append(f"{yolo_class_id} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}")

            except (ValueError, IndexError) as e:
                print(f"âš  è§£æé”™è¯¯ {annotation_path}: {line} -> {e}")
                continue

        return yolo_annotations

    def get_image_size(self, image_path):
        """è·å–å›¾åƒå°ºå¯¸"""
        try:
            from PIL import Image
            with Image.open(image_path) as img:
                return img.size  # (width, height)
        except Exception as e:
            print(f"âŒ æ— æ³•è·å–å›¾åƒå°ºå¯¸ {image_path}: {e}")
            return None

    def convert_dataset_split(self, split_name):
        """è½¬æ¢æ•´ä¸ªæ•°æ®é›†åˆ’åˆ†ï¼ˆtrain/val/testï¼‰"""
        print(f"\nğŸ”„ è½¬æ¢ {split_name} æ•°æ®é›†...")

        # åŸå§‹æ ‡æ³¨ç›®å½•
        orig_annotations_dir = path_manager.dataset_root / "annotations" / split_name
        # åŸå§‹å›¾åƒç›®å½•
        orig_images_dir = path_manager.dataset_root / "images" / split_name
        # è½¬æ¢åçš„æ ‡æ³¨ç›®å½•
        yolo_annotations_dir = path_manager.dataset_root / "labels" / split_name

        # åˆ›å»ºè¾“å‡ºç›®å½•
        yolo_annotations_dir.mkdir(parents=True, exist_ok=True)

        if not orig_annotations_dir.exists():
            print(f"âŒ åŸå§‹æ ‡æ³¨ç›®å½•ä¸å­˜åœ¨: {orig_annotations_dir}")
            return False

        if not orig_images_dir.exists():
            print(f"âŒ åŸå§‹å›¾åƒç›®å½•ä¸å­˜åœ¨: {orig_images_dir}")
            return False

        # è·å–æ‰€æœ‰æ ‡æ³¨æ–‡ä»¶
        annotation_files = list(orig_annotations_dir.glob("*.txt"))
        if not annotation_files:
            print(f"âŒ åœ¨ {split_name} ä¸­æ²¡æœ‰æ‰¾åˆ°æ ‡æ³¨æ–‡ä»¶")
            return False

        print(f"ğŸ“ æ‰¾åˆ° {len(annotation_files)} ä¸ªæ ‡æ³¨æ–‡ä»¶")

        success_count = 0
        error_count = 0

        # è½¬æ¢æ¯ä¸ªæ ‡æ³¨æ–‡ä»¶
        for annotation_file in tqdm(annotation_files, desc=f"è½¬æ¢ {split_name}"):
            try:
                # å¯¹åº”çš„å›¾åƒæ–‡ä»¶
                image_name = annotation_file.stem + ".jpg"
                image_path = orig_images_dir / image_name

                if not image_path.exists():
                    # å°è¯•å…¶ä»–å›¾åƒæ ¼å¼
                    for ext in ['.jpg', '.png', '.jpeg']:
                        alt_image_path = orig_images_dir / (annotation_file.stem + ext)
                        if alt_image_path.exists():
                            image_path = alt_image_path
                            break

                if not image_path.exists():
                    print(f"âš  æ‰¾ä¸åˆ°å›¾åƒæ–‡ä»¶: {image_name}")
                    error_count += 1
                    continue

                # è·å–å›¾åƒå°ºå¯¸
                image_size = self.get_image_size(image_path)
                if image_size is None:
                    error_count += 1
                    continue

                image_width, image_height = image_size

                # è½¬æ¢æ ‡æ³¨
                yolo_annotations = self.convert_annotation(annotation_file, image_width, image_height)

                # ä¿å­˜è½¬æ¢åçš„æ ‡æ³¨
                output_file = yolo_annotations_dir / annotation_file.name
                with open(output_file, 'w', encoding='utf-8') as f:
                    f.write('\n'.join(yolo_annotations))

                success_count += 1

            except Exception as e:
                print(f"âŒ è½¬æ¢å¤±è´¥ {annotation_file}: {e}")
                error_count += 1
                continue

        print(f"âœ… {split_name} è½¬æ¢å®Œæˆ: {success_count} æˆåŠŸ, {error_count} å¤±è´¥")
        return success_count > 0

    def create_dataset_yaml(self):


        config_content = f"""# YOLOæ ¼å¼çš„VisDroneæ•°æ®é›†é…ç½®
path: {path_manager.dataset_root}  # æ•°æ®é›†æ ¹ç›®å½•

# å›¾åƒå’Œæ ‡æ³¨è·¯å¾„
train: images/train
val: images/val
test: images/test_dev

# æ ‡æ³¨ç›®å½•ï¼ˆè½¬æ¢åçš„YOLOæ ¼å¼ï¼‰
train_labels: labels/train
val_labels: labels/val
test_labels: labels/test_dev

# ç±»åˆ«æ•°é‡
nc: {len(self.yolo_class_names)}

# ç±»åˆ«åç§°
names: {self.yolo_class_names}

# è®­ç»ƒå‚æ•°
img_size: 640
batch_size: 16
epochs: 80
"""

        with open(yolo_dataset_config, 'w', encoding='utf-8') as f:
            f.write(config_content)

        print(f"âœ… åˆ›å»ºYOLOæ•°æ®é›†é…ç½®: {yolo_dataset_config}")
        return yolo_dataset_config

    def convert_full_dataset(self):
        """è½¬æ¢æ•´ä¸ªæ•°æ®é›†"""
        print("ğŸš€ å¼€å§‹è½¬æ¢VisDroneæ•°æ®é›†ä¸ºYOLOæ ¼å¼")
        print("=" * 50)

        # éªŒè¯åŸå§‹æ•°æ®é›†ç»“æ„
        if not self.validate_original_dataset():
            return False

        # è½¬æ¢å„ä¸ªåˆ’åˆ†
        splits = ['train', 'val']
        # æ³¨æ„ï¼štest_devçš„æ ‡æ³¨é€šå¸¸ä¸å…¬å¼€ï¼Œæ‰€ä»¥å¯èƒ½æ— æ³•è½¬æ¢

        all_success = True
        for split in splits:
            if not self.convert_dataset_split(split):
                all_success = False

        if all_success:
            # åˆ›å»ºYOLOæ ¼å¼çš„é…ç½®æ–‡ä»¶
            # self.create_dataset_yaml()
            print("\nğŸ‰ æ•°æ®é›†è½¬æ¢å®Œæˆ!")
            print(f"ğŸ“ è½¬æ¢åçš„æ ‡æ³¨ä¿å­˜åœ¨: {path_manager.dataset_root / 'labels'}")

        else:
            print("\nâš  æ•°æ®é›†è½¬æ¢è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯ï¼Œè¯·æ£€æŸ¥ä¸Šè¿°è¾“å‡º")

        return all_success

    def validate_original_dataset(self):
        """éªŒè¯åŸå§‹æ•°æ®é›†ç»“æ„"""
        print("ğŸ” éªŒè¯åŸå§‹æ•°æ®é›†ç»“æ„...")

        required_dirs = [
            path_manager.dataset_root / "annotations" / "train",
            path_manager.dataset_root / "annotations" / "val",
            path_manager.dataset_root / "images" / "train",
            path_manager.dataset_root / "images" / "val"
        ]

        missing_dirs = []
        for dir_path in required_dirs:
            if not dir_path.exists():
                missing_dirs.append(str(dir_path))

        if missing_dirs:
            print("âŒ ç¼ºå°‘å¿…è¦çš„ç›®å½•:")
            for dir_path in missing_dirs:
                print(f"   - {dir_path}")
            return False

        # æ£€æŸ¥æ–‡ä»¶æ•°é‡
        train_ann_count = len(list((path_manager.dataset_root / "annotations" / "train").glob("*.txt")))
        val_ann_count = len(list((path_manager.dataset_root / "annotations" / "val").glob("*.txt")))

        print(f"âœ… è®­ç»ƒé›†æ ‡æ³¨æ–‡ä»¶: {train_ann_count} ä¸ª")
        print(f"âœ… éªŒè¯é›†æ ‡æ³¨æ–‡ä»¶: {val_ann_count} ä¸ª")

        if train_ann_count == 0 or val_ann_count == 0:
            print("âŒ æ ‡æ³¨æ–‡ä»¶æ•°é‡ä¸º0ï¼Œè¯·æ£€æŸ¥æ•°æ®é›†")
            return False

        return True

    def statistics(self):
        """ç»Ÿè®¡æ•°æ®é›†ä¿¡æ¯"""
        print("\nğŸ“Š æ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯")
        print("=" * 30)

        for split in ['train', 'val']:
            labels_dir = path_manager.dataset_root / "labels" / split
            if not labels_dir.exists():
                print(f"âŒ {split} çš„æ ‡ç­¾ç›®å½•ä¸å­˜åœ¨")
                continue

            label_files = list(labels_dir.glob("*.txt"))
            total_objects = 0
            class_counts = {i: 0 for i in range(len(self.yolo_class_names))}

            for label_file in label_files:
                with open(label_file, 'r', encoding='utf-8') as f:
                    lines = f.readlines()
                    total_objects += len(lines)
                    for line in lines:
                        parts = line.strip().split()
                        if parts:
                            class_id = int(parts[0])
                            if class_id in class_counts:
                                class_counts[class_id] += 1

            print(f"\n{split.upper()} é›†:")
            print(f"  å›¾åƒæ•°é‡: {len(label_files)}")
            print(f"  ç›®æ ‡æ€»æ•°: {total_objects}")
            print(f"  å„ç±»åˆ«æ•°é‡:")
            for class_id, count in class_counts.items():
                if count > 0:
                    print(f"    {self.yolo_class_names[class_id]}: {count}")


def convert_visdrone_to_yolo():
    """è½¬æ¢VisDroneæ•°æ®é›†ä¸ºYOLOæ ¼å¼"""
    converter = AnnotationConverter()
    return converter.convert_full_dataset()


def show_dataset_statistics():
    """æ˜¾ç¤ºæ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯"""
    converter = AnnotationConverter()
    converter.statistics()


if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description='VisDroneæ ‡æ³¨æ ¼å¼è½¬æ¢å™¨')
    parser.add_argument('--convert', action='store_true', help='è½¬æ¢æ•°æ®é›†')
    parser.add_argument('--stats', action='store_true', help='æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯')

    args = parser.parse_args()

    if args.convert:
        convert_visdrone_to_yolo()
    elif args.stats:
        show_dataset_statistics()
    else:
        print("ç”¨æ³•:")
        print("  python annotation_converter.py --convert   # è½¬æ¢æ•°æ®é›†")
        print("  python annotation_converter.py --stats     # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯")