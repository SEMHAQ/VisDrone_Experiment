#!/usr/bin/env python3
"""
æ¶ˆèå®éªŒä¸»è„šæœ¬ - å®Œæ•´ç‰ˆæœ¬
"""

import os
import sys
from pathlib import Path

project_root = Path(__file__).parent.parent
sys.path.append(str(project_root))

import torch
from ultralytics import YOLO
from utils.path_manager import path_manager
from models.hook_integration import create_ema_model, create_bifpn_model, create_full_model


class AblationStudy:
    def __init__(self):
        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'
        self.experiments = {

            'baseline': {
                'name': 'baseline',
                'description': 'åŸå§‹YOLOv8s',
                'train_fn': self.train_baseline,
                'evaluate_fn': self.evaluate_model
            },

            'ema': {
                'name': 'ema',
                'description': 'YOLOv8s + EMAæ³¨æ„åŠ›',
                'train_fn': self.train_ema,
                'evaluate_fn': self.evaluate_model
            },



            'bifpn': {
                'name': 'bifpn',
                'description': 'YOLOv8s + BiFPN',
                'train_fn': self.train_bifpn,
                'evaluate_fn': self.evaluate_model
            },

            'full': {
                'name': 'full',
                'description': 'YOLOv8s + EMA + BiFPN',
                'train_fn': self.train_full,
                'evaluate_fn': self.evaluate_model
            },
        }

    def get_train_config(self, exp_name):
        """è·å–è®­ç»ƒé…ç½®"""
        return {
            'data': str(path_manager.dataset_config),
            'epochs': 80,
            'imgsz': 640,
            'batch': 16,
            'patience': 20,
            'device': self.device,
            'workers': 4,
            'save': True,
            'exist_ok': True,
            'verbose': False,
            'project': str(path_manager.runs_dir),
            'name': exp_name
        }

    def train_baseline(self, exp_name):
        """è®­ç»ƒåŸºå‡†æ¨¡å‹"""
        try:
            model = YOLO('scripts/yolov8s.pt')
            config = self.get_train_config(exp_name)
            results = model.train(**config)
            return True, results
        except Exception as e:
            return False, str(e)

    def train_ema(self, exp_name):
        """è®­ç»ƒEMAæ¨¡å‹"""
        try:
            integrator = create_ema_model()
            config = self.get_train_config(exp_name)
            results = integrator.model.train(**config)
            integrator.cleanup()
            return True, results
        except Exception as e:
            return False, str(e)

    def train_bifpn(self, exp_name):
        """è®­ç»ƒBiFPNæ¨¡å‹"""
        try:
            integrator = create_bifpn_model()
            config = self.get_train_config(exp_name)
            results = integrator.model.train(**config)
            integrator.cleanup()
            return True, results
        except Exception as e:
            return False, str(e)

    def train_full(self, exp_name):
        """è®­ç»ƒå®Œæ•´æ¨¡å‹"""
        try:
            integrator = create_full_model()
            config = self.get_train_config(exp_name)
            results = integrator.model.train(**config)
            integrator.cleanup()
            return True, results
        except Exception as e:
            return False, str(e)

    def evaluate_model(self, exp_name):
        """è¯„ä¼°æ¨¡å‹"""
        try:
            exp_dir = path_manager.get_experiment_dir(exp_name)
            weights_file = exp_dir / "weights" / "best.pt"

            if not weights_file.exists():
                return False, "æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨"

            model = YOLO(str(weights_file))
            metrics = model.val(
                data=str(path_manager.dataset_config),
                split='val',
                imgsz=640,
                batch=16,
                conf=0.001,
                iou=0.6,
                verbose=False
            )

            results = {
                'map50': float(metrics.box.map50),
                'map': float(metrics.box.map),
                'precision': float(metrics.box.precision.mean()),
                'recall': float(metrics.box.recall.mean()),
                'f1_score': self.calculate_f1_score(
                    float(metrics.box.precision.mean()),
                    float(metrics.box.recall.mean())
                )
            }

            return True, results

        except Exception as e:
            return False, str(e)

    def calculate_f1_score(self, precision, recall):
        """è®¡ç®—F1åˆ†æ•°"""
        if precision + recall == 0:
            return 0.0
        return 2 * (precision * recall) / (precision + recall)

    def run(self):
        """è¿è¡Œæ¶ˆèå®éªŒ"""
        print("ğŸ§ª å¼€å§‹æ¶ˆèå®éªŒ")
        print("=" * 60)
        print("å®éªŒé¡ºåº:")
        for exp_key, config in self.experiments.items():
            print(f"- {exp_key}: {config['description']}")
        print("=" * 60)

        results = {}

        for exp_key, config in self.experiments.items():
            exp_name = config['name']
            description = config['description']

            print(f"\nğŸ¯ å®éªŒ {exp_key}: {description}")
            print("-" * 50)

            # æ£€æŸ¥æ˜¯å¦å·²è®­ç»ƒ
            exp_dir = path_manager.get_experiment_dir(exp_name)
            weights_file = exp_dir / "weights" / "best.pt"

            if weights_file.exists():
                print("âœ… æ¨¡å‹å·²è®­ç»ƒï¼Œè·³è¿‡è®­ç»ƒé˜¶æ®µ")
                train_success, train_result = True, "å·²è®­ç»ƒ"
            else:
                # è®­ç»ƒæ¨¡å‹
                print("å¼€å§‹è®­ç»ƒ...")
                train_success, train_result = config['train_fn'](exp_name)

                if train_success:
                    print("âœ… è®­ç»ƒå®Œæˆ")
                else:
                    print(f"âŒ è®­ç»ƒå¤±è´¥: {train_result}")

            # è¯„ä¼°æ¨¡å‹
            if train_success:
                print("å¼€å§‹è¯„ä¼°...")
                eval_success, eval_result = config['evaluate_fn'](exp_name)

                if eval_success:
                    print("âœ… è¯„ä¼°å®Œæˆ")
                    results[exp_key] = {
                        'status': 'success',
                        'metrics': eval_result,
                        'train_result': train_result
                    }
                else:
                    print(f"âŒ è¯„ä¼°å¤±è´¥: {eval_result}")
                    results[exp_key] = {
                        'status': 'evaluation_failed',
                        'error': eval_result,
                        'train_result': train_result
                    }
            else:
                results[exp_key] = {
                    'status': 'training_failed',
                    'error': train_result
                }

        # åˆ†æç»“æœ
        self.analyze_results(results)
        return results

    def analyze_results(self, results):
        """åˆ†æå®éªŒç»“æœ"""
        print("\nğŸ“Š å®éªŒç»“æœåˆ†æ")
        print("=" * 60)

        successful_experiments = {}
        for exp_key, result in results.items():
            if result['status'] == 'success':
                successful_experiments[exp_key] = result['metrics']

        if not successful_experiments:
            print("âŒ æ²¡æœ‰æˆåŠŸçš„å®éªŒ")
            return

        # æ˜¾ç¤ºæ€§èƒ½å¯¹æ¯”
        print("\næ€§èƒ½å¯¹æ¯”:")
        print("| å®éªŒ | mAP@0.5 | mAP@0.5:0.95 | ç²¾ç¡®ç‡ | å¬å›ç‡ | F1åˆ†æ•° |")
        print("|------|---------|--------------|--------|--------|--------|")

        for exp_key, metrics in successful_experiments.items():
            print(f"| {exp_key} | {metrics['map50']:.4f} | {metrics['map']:.4f} | "
                  f"{metrics['precision']:.4f} | {metrics['recall']:.4f} | {metrics['f1_score']:.4f} |")

        # è®¡ç®—æ”¹è¿›ç™¾åˆ†æ¯”
        baseline_metrics = successful_experiments.get('baseline')
        if baseline_metrics:
            print("\næ”¹è¿›ç™¾åˆ†æ¯” (ç›¸å¯¹äºåŸºå‡†æ¨¡å‹):")
            print("| å®éªŒ | mAP@0.5æ”¹è¿› | mAPæ”¹è¿› | F1æ”¹è¿› |")
            print("|------|------------|---------|--------|")

            for exp_key, metrics in successful_experiments.items():
                if exp_key != 'baseline':
                    map50_improvement = ((metrics['map50'] - baseline_metrics['map50']) / baseline_metrics[
                        'map50']) * 100
                    map_improvement = ((metrics['map'] - baseline_metrics['map']) / baseline_metrics['map']) * 100
                    f1_improvement = ((metrics['f1_score'] - baseline_metrics['f1_score']) / baseline_metrics[
                        'f1_score']) * 100

                    print(
                        f"| {exp_key} | {map50_improvement:+.2f}% | {map_improvement:+.2f}% | {f1_improvement:+.2f}% |")

        # ç”ŸæˆæŠ¥å‘Š
        self.generate_report(results, successful_experiments)

    def generate_report(self, results, successful_experiments):
        """ç”Ÿæˆå®éªŒæŠ¥å‘Š"""
        report_dir = Path("results")
        report_dir.mkdir(parents=True, exist_ok=True)

        report_path = report_dir / "ablation_study_report.md"

        with open(report_path, 'w', encoding='utf-8') as f:
            f.write("# VisDroneæ¶ˆèå®éªŒæŠ¥å‘Š\n\n")
            f.write("## å®éªŒæ¦‚è§ˆ\n\n")

            for exp_key, result in results.items():
                status_icon = "âœ…" if result['status'] == 'success' else "âŒ"
                f.write(f"- {status_icon} **{exp_key}**: {self.experiments[exp_key]['description']}\n")
                if result['status'] != 'success':
                    f.write(f"  - çŠ¶æ€: {result['status']}\n")
                    if 'error' in result:
                        f.write(f"  - é”™è¯¯: {result['error']}\n")

            if successful_experiments:
                f.write("\n## æ€§èƒ½å¯¹æ¯”\n\n")
                f.write("| å®éªŒ | mAP@0.5 | mAP@0.5:0.95 | ç²¾ç¡®ç‡ | å¬å›ç‡ | F1åˆ†æ•° |\n")
                f.write("|------|---------|--------------|--------|--------|--------|\n")

                for exp_key, metrics in successful_experiments.items():
                    f.write(f"| {exp_key} | {metrics['map50']:.4f} | {metrics['map']:.4f} | "
                            f"{metrics['precision']:.4f} | {metrics['recall']:.4f} | {metrics['f1_score']:.4f} |\n")

            f.write("\n## ç»“è®º\n\n")
            f.write("é€šè¿‡æ¶ˆèå®éªŒéªŒè¯äº†å„ä¸ªæ”¹è¿›æ¨¡å—çš„æœ‰æ•ˆæ€§ã€‚\n")

        print(f"âœ… å®éªŒæŠ¥å‘Šå·²ç”Ÿæˆ: {report_path}")


def main():
    """ä¸»å‡½æ•°"""
    # éªŒè¯ç¯å¢ƒ
    if not path_manager.validate_paths():
        print("âŒ ç¯å¢ƒéªŒè¯å¤±è´¥")
        return

    print("ğŸ§ª VisDroneç›®æ ‡æ£€æµ‹æ¶ˆèå®éªŒ")
    print("=" * 60)

    study = AblationStudy()
    results = study.run()

    print("\nğŸ¯ æ¶ˆèå®éªŒå®Œæˆ!")
    return results


if __name__ == "__main__":
    main()