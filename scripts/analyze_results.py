#!/usr/bin/env python3
"""
å®Œæ•´ç»“æœåˆ†æè„šæœ¬
"""

import os
import sys
import json
import yaml
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.append(str(project_root))

from utils.path_manager import path_manager


class ComprehensiveAnalyzer:
    """ç»¼åˆåˆ†æå™¨"""

    def __init__(self):
        self.results_data = {}
        self.experiments = ['baseline', 'ema_attention', 'bifpn', 'full_model']

    def collect_all_metrics(self):
        """æ”¶é›†æ‰€æœ‰å®éªŒçš„æŒ‡æ ‡"""
        print("ğŸ“Š æ”¶é›†å®éªŒç»“æœæ•°æ®...")

        for exp_name in self.experiments:
            exp_dir = path_manager.get_experiment_dir(exp_name)

            # å°è¯•ä»ä¸åŒä½ç½®æ”¶é›†æ•°æ®
            metrics = self._collect_metrics_from_files(exp_dir, exp_name)
            self.results_data[exp_name] = metrics

            print(f"   {exp_name}: {len(metrics)} ä¸ªæŒ‡æ ‡æ”¶é›†å®Œæˆ")

    def _collect_metrics_from_files(self, exp_dir, exp_name):
        """ä»æ–‡ä»¶æ”¶é›†æŒ‡æ ‡"""
        metrics = {
            'experiment': exp_name,
            'timestamp': datetime.now().isoformat()
        }

        # 1. ä»è¯„ä¼°ç»“æœæ–‡ä»¶è¯»å–
        eval_file = exp_dir / "metrics" / "evaluation_results.txt"
        if eval_file.exists():
            metrics.update(self._parse_evaluation_file(eval_file))

        # 2. ä»è®­ç»ƒæ—¥å¿—è¯»å–
        train_log = exp_dir / "train_log.txt"
        if not train_log.exists():
            # å°è¯•æŸ¥æ‰¾å…¶ä»–æ—¥å¿—æ–‡ä»¶
            for log_file in exp_dir.glob("*.log"):
                train_log = log_file
                break

        if train_log.exists():
            metrics.update(self._parse_training_log(train_log))

        # 3. ä»YOLOç»“æœæ–‡ä»¶è¯»å–
        results_file = exp_dir / "results.csv"
        if results_file.exists():
            metrics.update(self._parse_results_csv(results_file))

        # 4. æ£€æŸ¥æ¨¡å‹æ–‡ä»¶å¤§å°
        weights_file = exp_dir / "weights" / "best.pt"
        if weights_file.exists():
            metrics['model_size_mb'] = weights_file.stat().st_size / (1024 * 1024)

        return metrics

    def _parse_evaluation_file(self, file_path):
        """è§£æè¯„ä¼°ç»“æœæ–‡ä»¶"""
        metrics = {}
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                for line in f:
                    if ':' in line:
                        key, value = line.split(':', 1)
                        key = key.strip().lower().replace(' ', '_')
                        value = value.strip()

                        # è½¬æ¢ä¸ºæ•°å€¼
                        try:
                            if '.' in value:
                                metrics[key] = float(value)
                            else:
                                metrics[key] = int(value)
                        except ValueError:
                            metrics[key] = value
        except Exception as e:
            print(f"âš  è§£æè¯„ä¼°æ–‡ä»¶å¤±è´¥ {file_path}: {e}")

        return metrics

    def _parse_training_log(self, file_path):
        """è§£æè®­ç»ƒæ—¥å¿—"""
        metrics = {}
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                lines = f.readlines()
                # ç®€å•çš„è§£æé€»è¾‘ï¼Œå®é™…åº”è¯¥æ›´å¤æ‚
                for line in lines:
                    if 'epoch' in line.lower() and 'time' in line.lower():
                        # æå–è®­ç»ƒæ—¶é—´ä¿¡æ¯
                        pass
        except Exception as e:
            print(f"âš  è§£æè®­ç»ƒæ—¥å¿—å¤±è´¥ {file_path}: {e}")

        return metrics

    def _parse_results_csv(self, file_path):
        """è§£æYOLOç»“æœCSV"""
        metrics = {}
        try:
            df = pd.read_csv(file_path)
            if not df.empty:
                # è·å–æœ€åä¸€è¡Œï¼ˆæœ€ç»ˆç»“æœï¼‰
                last_row = df.iloc[-1]
                metrics.update({
                    'train_loss': last_row.get('train/loss', 0),
                    'val_loss': last_row.get('val/loss', 0),
                    'precision': last_row.get('metrics/precision', 0),
                    'recall': last_row.get('metrics/recall', 0),
                    'map50': last_row.get('metrics/mAP50', 0),
                    'map50_95': last_row.get('metrics/mAP50-95', 0)
                })
        except Exception as e:
            print(f"âš  è§£æç»“æœCSVå¤±è´¥ {file_path}: {e}")

        return metrics

    def create_comparison_table(self):
        """åˆ›å»ºå¯¹æ¯”è¡¨æ ¼"""
        if not self.results_data:
            print("âŒ æ²¡æœ‰å¯ç”¨çš„ç»“æœæ•°æ®")
            return None

        # å‡†å¤‡æ•°æ®
        rows = []
        for exp_name, metrics in self.results_data.items():
            row = {
                'å®éªŒåç§°': exp_name,
                'mAP@0.5': metrics.get('map@0.5', metrics.get('map50', 0)),
                'mAP@0.5:0.95': metrics.get('map@0.5:0.95', metrics.get('map50_95', 0)),
                'ç²¾ç¡®ç‡': metrics.get('precision', 0),
                'å¬å›ç‡': metrics.get('recall', 0),
                'F1åˆ†æ•°': self._calculate_f1_score(metrics.get('precision', 0), metrics.get('recall', 0)),
                'æ¨¡å‹å¤§å°(MB)': metrics.get('model_size_mb', 0),
                'çŠ¶æ€': 'å·²å®Œæˆ' if metrics.get('model_size_mb', 0) > 0 else 'æœªå®Œæˆ'
            }
            rows.append(row)

        # åˆ›å»ºDataFrame
        df = pd.DataFrame(rows)

        # ä¿å­˜ä¸ºCSV
        output_dir = Path("results")
        output_dir.mkdir(parents=True, exist_ok=True)

        csv_path = output_dir / "experiment_comparison.csv"
        df.to_csv(csv_path, index=False, encoding='utf-8-sig')
        print(f"âœ… å¯¹æ¯”è¡¨æ ¼å·²ä¿å­˜: {csv_path}")

        # æ‰“å°è¡¨æ ¼
        print("\nğŸ“‹ å®éªŒå¯¹æ¯”ç»“æœ:")
        print("=" * 80)
        print(df.to_string(index=False))

        return df

    def _calculate_f1_score(self, precision, recall):
        """è®¡ç®—F1åˆ†æ•°"""
        if precision + recall == 0:
            return 0.0
        return 2 * (precision * recall) / (precision + recall)

    def generate_visualizations(self, df):
        """ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨"""
        if df is None or df.empty:
            print("âŒ æ²¡æœ‰æ•°æ®å¯ç”Ÿæˆå›¾è¡¨")
            return

        print("\nğŸ“ˆ ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨...")

        # è®¾ç½®ä¸­æ–‡å­—ä½“
        plt.rcParams['font.sans-serif'] = ['SimHei']
        plt.rcParams['axes.unicode_minus'] = False

        # åˆ›å»ºå›¾è¡¨ç›®å½•
        viz_dir = Path("results/visualizations")
        viz_dir.mkdir(parents=True, exist_ok=True)

        # 1. ç²¾åº¦å¯¹æ¯”æŸ±çŠ¶å›¾
        plt.figure(figsize=(12, 8))

        plt.subplot(2, 2, 1)
        sns.barplot(data=df, x='å®éªŒåç§°', y='mAP@0.5')
        plt.title('mAP@0.5 å¯¹æ¯”')
        plt.xticks(rotation=45)

        plt.subplot(2, 2, 2)
        sns.barplot(data=df, x='å®éªŒåç§°', y='mAP@0.5:0.95')
        plt.title('mAP@0.5:0.95 å¯¹æ¯”')
        plt.xticks(rotation=45)

        plt.subplot(2, 2, 3)
        sns.barplot(data=df, x='å®éªŒåç§°', y='ç²¾ç¡®ç‡')
        plt.title('ç²¾ç¡®ç‡å¯¹æ¯”')
        plt.xticks(rotation=45)

        plt.subplot(2, 2, 4)
        sns.barplot(data=df, x='å®éªŒåç§°', y='å¬å›ç‡')
        plt.title('å¬å›ç‡å¯¹æ¯”')
        plt.xticks(rotation=45)

        plt.tight_layout()
        plt.savefig(viz_dir / 'accuracy_comparison.png', dpi=300, bbox_inches='tight')
        plt.close()

        # 2. ç»¼åˆæŒ‡æ ‡é›·è¾¾å›¾
        self._create_radar_chart(df, viz_dir)

        print(f"âœ… å¯è§†åŒ–å›¾è¡¨å·²ä¿å­˜: {viz_dir}")

    def _create_radar_chart(self, df, viz_dir):
        """åˆ›å»ºé›·è¾¾å›¾"""
        try:
            # é€‰æ‹©æ•°å€¼å‹åˆ—
            numeric_cols = ['mAP@0.5', 'mAP@0.5:0.95', 'ç²¾ç¡®ç‡', 'å¬å›ç‡', 'F1åˆ†æ•°']
            plot_data = df[['å®éªŒåç§°'] + numeric_cols].copy()

            # å½’ä¸€åŒ–æ•°æ®
            for col in numeric_cols:
                if plot_data[col].max() > 0:
                    plot_data[col] = plot_data[col] / plot_data[col].max()

            # åˆ›å»ºé›·è¾¾å›¾
            fig = plt.figure(figsize=(10, 8))
            ax = fig.add_subplot(111, polar=True)

            # è®¾ç½®è§’åº¦
            angles = [n / float(len(numeric_cols)) * 2 * np.pi for n in range(len(numeric_cols))]
            angles += angles[:1]  # é—­åˆ

            # ç»˜åˆ¶æ¯ä¸ªå®éªŒ
            for idx, row in plot_data.iterrows():
                values = row[numeric_cols].tolist()
                values += values[:1]  # é—­åˆ
                ax.plot(angles, values, 'o-', linewidth=2, label=row['å®éªŒåç§°'])
                ax.fill(angles, values, alpha=0.1)

            # è®¾ç½®æ ‡ç­¾
            ax.set_xticks(angles[:-1])
            ax.set_xticklabels(numeric_cols)
            ax.set_ylim(0, 1)
            plt.title('å®éªŒæ€§èƒ½é›·è¾¾å›¾', size=14, y=1.08)
            plt.legend(loc='upper right', bbox_to_anchor=(1.3, 1.0))

            plt.savefig(viz_dir / 'radar_chart.png', dpi=300, bbox_inches='tight')
            plt.close()

        except Exception as e:
            print(f"âš  åˆ›å»ºé›·è¾¾å›¾å¤±è´¥: {e}")

    def generate_comprehensive_report(self):
        """ç”Ÿæˆç»¼åˆåˆ†ææŠ¥å‘Š"""
        print("\nğŸ“„ ç”Ÿæˆç»¼åˆåˆ†ææŠ¥å‘Š...")

        report_dir = Path("results")
        report_dir.mkdir(parents=True, exist_ok=True)

        # åˆ›å»ºæŠ¥å‘Š
        report_content = self._build_report_content()

        # ä¿å­˜MarkdownæŠ¥å‘Š
        md_report = report_dir / "comprehensive_analysis_report.md"
        with open(md_report, 'w', encoding='utf-8') as f:
            f.write(report_content)

        # ä¿å­˜JSONæ•°æ®
        json_data = report_dir / "experiment_results.json"
        with open(json_data, 'w', encoding='utf-8') as f:
            json.dump(self.results_data, f, indent=2, ensure_ascii=False)

        print(f"âœ… åˆ†ææŠ¥å‘Šå·²ç”Ÿæˆ:")
        print(f"   ğŸ“ MarkdownæŠ¥å‘Š: {md_report}")
        print(f"   ğŸ“Š JSONæ•°æ®: {json_data}")

        return md_report

    def _build_report_content(self):
        """æ„å»ºæŠ¥å‘Šå†…å®¹"""
        content = "# VisDroneå®éªŒç»¼åˆåˆ†ææŠ¥å‘Š\n\n"
        content += f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n"

        content += "## å®éªŒæ¦‚è§ˆ\n\n"
        content += "| å®éªŒ | çŠ¶æ€ | mAP@0.5 | mAP@0.5:0.95 | ç²¾ç¡®ç‡ | å¬å›ç‡ | F1åˆ†æ•° |\n"
        content += "|------|------|---------|--------------|--------|--------|--------|\n"

        for exp_name, metrics in self.results_data.items():
            content += f"| {exp_name} | "
            content += "âœ… å·²å®Œæˆ | " if metrics.get('model_size_mb', 0) > 0 else "â³ è¿›è¡Œä¸­ | "
            content += f"{metrics.get('map@0.5', metrics.get('map50', 0)):.4f} | "
            content += f"{metrics.get('map@0.5:0.95', metrics.get('map50_95', 0)):.4f} | "
            content += f"{metrics.get('precision', 0):.4f} | "
            content += f"{metrics.get('recall', 0):.4f} | "
            content += f"{self._calculate_f1_score(metrics.get('precision', 0), metrics.get('recall', 0)):.4f} |\n"

        content += "\n## è¯¦ç»†åˆ†æ\n\n"

        # æ€§èƒ½åˆ†æ
        content += "### æ€§èƒ½åˆ†æ\n\n"
        completed_exps = {k: v for k, v in self.results_data.items() if v.get('model_size_mb', 0) > 0}

        if completed_exps:
            best_map50 = max(metrics.get('map@0.5', metrics.get('map50', 0)) for metrics in completed_exps.values())
            best_exp = [k for k, v in completed_exps.items()
                        if v.get('map@0.5', v.get('map50', 0)) == best_map50][0]

            content += f"- **æœ€ä½³æ€§èƒ½æ¨¡å‹**: {best_exp} (mAP@0.5: {best_map50:.4f})\n"
            content += f"- **ç›¸å¯¹åŸºå‡†æå‡**: {((best_map50 - completed_exps['baseline'].get('map@0.5', completed_exps['baseline'].get('map50', 0))) / completed_exps['baseline'].get('map@0.5', completed_exps['baseline'].get('map50', 0)) * 100):.2f}%\n\n"

        # æ”¹è¿›æ•ˆæœåˆ†æ
        content += "### æ”¹è¿›æ•ˆæœåˆ†æ\n\n"
        content += "1. **åŸºå‡†æ¨¡å‹**: ä½œä¸ºæ€§èƒ½åŸºå‡†\n"
        content += "2. **+EMAæ³¨æ„åŠ›**: å…³æ³¨ç‰¹å¾å¢å¼ºæ•ˆæœ\n"
        content += "3. **+BiFPN**: å…³æ³¨å¤šå°ºåº¦ç‰¹å¾èåˆæ•ˆæœ\n"
        content += "4. **å®Œæ•´æ¨¡å‹**: ç»¼åˆæ”¹è¿›æ•ˆæœ\n\n"

        content += "## ç»“è®ºä¸å»ºè®®\n\n"
        content += "åŸºäºå½“å‰å®éªŒç»“æœï¼Œå»ºè®®ï¼š\n\n"
        content += "1. ç»§ç»­å®Œæˆæ‰€æœ‰å®éªŒçš„è®­ç»ƒ\n"
        content += "2. å¯¹è¡¨ç°æœ€ä½³çš„æ”¹è¿›æ¨¡å—è¿›è¡Œæ·±å…¥åˆ†æ\n"
        content += "3. è€ƒè™‘æ¨¡å‹å¤æ‚åº¦å’Œæ¨ç†é€Ÿåº¦çš„å¹³è¡¡\n"

        return content


def run_analysis():
    """è¿è¡Œç»“æœåˆ†æ"""
    analyzer = ComprehensiveAnalyzer()

    # æ”¶é›†æ•°æ®
    analyzer.collect_all_metrics()

    # ç”Ÿæˆå¯¹æ¯”è¡¨æ ¼
    df = analyzer.create_comparison_table()

    # ç”Ÿæˆå¯è§†åŒ–
    analyzer.generate_visualizations(df)

    # ç”ŸæˆæŠ¥å‘Š
    report_path = analyzer.generate_comprehensive_report()

    print(f"\nğŸ‰ ç»“æœåˆ†æå®Œæˆ!")
    print(f"ğŸ“ æ‰€æœ‰ç»“æœä¿å­˜åœ¨: results/ ç›®å½•")

    return report_path


if __name__ == "__main__":
    # ç¡®ä¿numpyå¯ç”¨
    try:
        import numpy as np
    except ImportError:
        print("âŒ éœ€è¦å®‰è£…numpy: pip install numpy")
        sys.exit(1)

    run_analysis()